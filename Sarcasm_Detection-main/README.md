
# Sarcasm Detection Using Traditional and Transformer Models

## Overview

This project compares traditional machine learning models (SVM, Random Forest, Logistic Regression) with transformer-based models like BERT for sarcasm detection in text data. BERT with GLoVe embeddings achieved the best performance, with an accuracy of 92%.

## Methods

- **Traditional Models**: SVM, Random Forest, Logistic Regression.
- **Transformer Models**: BERT, BERT + GLoVe embeddings.
- **Data Preprocessing**: Tokenization, stopword removal, feature extraction (word embeddings, POS tags, sentiment analysis).

## Results

- **Best Model**: BERT with GLoVe, 92% accuracy.
- **Evaluation**: Compared on accuracy, precision, recall, and F1-score.

